use cubecl::TestRuntime;
use cubecl::prelude::*;
use cubecl::std::tensor::TensorHandle;
use cubek_matmul::definition::AvailableLineSizes;
use cubek_matmul::definition::MatmulIdent;
use cubek_matmul::definition::MatrixLayout;
use cubek_matmul::launch::ConcreteOutputFactory;
use cubek_matmul::launch::ConcreteOutputFactory as _;

use cubek_matmul::components::batch::{BatchConfig, BatchMatmulFamily};
use cubek_matmul::definition::MatmulElems;
use cubek_matmul::definition::{MatmulProblem, TilingBlueprint};
use cubek_matmul::launch::ConcreteInputsFactory;
use cubek_matmul::launch::MatmulInputHandleRef;
use cubek_matmul::launch::TensorArgs;
use cubek_matmul::launch::TensorInputs;
use cubek_matmul::launch::TensorMapArgs;
use cubek_matmul::launch::TensorMapInputs;
use cubek_matmul::launch::TensorOutput;
use cubek_matmul::routines::Routine;
use cubek_test_utils::HostData;
use cubek_test_utils::current_test_mode;
use cubek_test_utils::{Distribution, RandomInputSpec, SimpleInputSpec, TestInput};

use crate::suite::assert_result;
use crate::suite::layout_to_stride_spec;

pub enum InputRepresentation {
    Normal,
    Tma,
}

#[allow(unused)]
/// Test the correctness of the specified Matmul on the given device,
/// against a naive CPU implementation over the given problem
pub fn test_matmul_algorithm<A: Routine<Blueprint = TilingBlueprint>>(
    client: ComputeClient<TestRuntime>,
    mut problem: MatmulProblem,
    selection: A::Blueprint,
    input_representation: InputRepresentation,
) {
    let (lhs, lhs_data) = TestInput::random(
        client.clone(),
        problem.lhs_shape.clone(),
        *problem.global_dtypes.lhs,
        1234,
        Distribution::Uniform(-1., 1.),
        layout_to_stride_spec(problem.lhs_layout),
    )
    .generate_with_f32_host_data();

    let (rhs, rhs_data) = TestInput::random(
        client.clone(),
        problem.rhs_shape.clone(),
        *problem.global_dtypes.rhs,
        5678,
        Distribution::Uniform(-1., 1.),
        layout_to_stride_spec(problem.rhs_layout),
    )
    .generate_with_f32_host_data();

    let out = TestInput::zeros(
        client.clone(),
        problem.out_shape.clone(),
        *problem.global_dtypes.out,
        layout_to_stride_spec(MatrixLayout::RowMajor),
    )
    .generate_without_host_data();

    problem.lhs_strides = lhs.strides.clone();
    problem.rhs_strides = rhs.strides.clone();

    let lhs_handle = MatmulInputHandleRef::Normal(lhs.as_ref(), *problem.global_dtypes.lhs);
    let rhs_handle = MatmulInputHandleRef::Normal(rhs.as_ref(), *problem.global_dtypes.rhs);
    let out_handle = out.as_ref();

    let all_elems = MatmulElems::from_globals(&problem.global_dtypes.clone());

    if launch_matmul_algorithm::<A>(
        &client,
        &problem,
        selection,
        &all_elems,
        input_representation,
        lhs_handle,
        rhs_handle,
        out_handle,
    ) {
        assert_result(&lhs_data, &rhs_data, &problem, &client, &out, all_elems);
    }
}

/// Returns whether execution succeeded
#[allow(clippy::too_many_arguments)]
pub fn launch_matmul_algorithm<A: Routine<Blueprint = TilingBlueprint>>(
    client: &ComputeClient<TestRuntime>,
    problem: &MatmulProblem,
    selection: A::Blueprint,
    dtypes: &MatmulElems,
    input_representation: InputRepresentation,
    lhs: MatmulInputHandleRef<TestRuntime>,
    rhs: MatmulInputHandleRef<TestRuntime>,
    out: TensorHandleRef<TestRuntime>,
) -> bool {
    let line_sizes = AvailableLineSizes::from_type_sizes(
        client,
        dtypes.lhs_global.size(),
        dtypes.rhs_global.size(),
        dtypes.acc_global.size(),
    );
    let line_sizes = match input_representation {
        InputRepresentation::Normal => line_sizes
            .filter_lhs_with_tensor(lhs.data().strides, lhs.data().shape, problem.lhs_layout)
            .filter_rhs_with_tensor(rhs.data().strides, rhs.data().shape, problem.rhs_layout)
            .filter_out_with_tensor(out.strides, out.shape)
            .pick_max()
            .unwrap(),
        InputRepresentation::Tma => line_sizes
            .filter_lhs(|ls| *ls == 1)
            .filter_rhs(|ls| *ls == 1)
            .pick_max()
            .unwrap(),
    };

    let config = match A::expand_config(client, problem, &selection, &line_sizes, dtypes) {
        Ok(config) => config,
        Err(err) => {
            if current_test_mode().should_fail_on_test_compilation_fail() {
                panic!("Can't launch the test: {err}");
            }
            return false;
        }
    };

    let props = &client.properties().hardware;
    if !props.max_cube_dim.can_contain(config.cube_dim())
        || config.cube_dim().num_elems() > props.max_units_per_cube
    {
        println!("Skipping test, too many resources requested");
        return false;
    }

    let output = <TensorOutput<_> as ConcreteOutputFactory<A>>::create(
        client,
        &out,
        &selection,
        problem,
        &line_sizes,
        config,
        dtypes,
    );

    let cube_count_plan = config.cube_count_plan(
        problem,
        &client.properties().hardware.max_cube_count.clone(),
    );

    match input_representation {
        InputRepresentation::Normal => {
            let inputs = <TensorInputs<_, _, _> as ConcreteInputsFactory<A>>::create(
                client,
                &lhs,
                &rhs,
                &selection,
                problem,
                &line_sizes,
                config,
                dtypes,
            );

            unsafe {
                A::BatchMatmul::launch_unchecked::<TensorArgs, TestRuntime>(
                    client,
                    config.cube_dim(),
                    cube_count_plan.resolve(),
                    inputs,
                    output,
                    cube_count_plan.as_args(),
                    config,
                    dtypes,
                )
            }
        }
        InputRepresentation::Tma => {
            let inputs = <TensorMapInputs<_, _, _> as ConcreteInputsFactory<A>>::create(
                client,
                &lhs,
                &rhs,
                &selection,
                problem,
                &line_sizes,
                config,
                dtypes,
            );

            unsafe {
                A::BatchMatmul::launch_unchecked::<TensorMapArgs, TestRuntime>(
                    client,
                    config.cube_dim(),
                    cube_count_plan.resolve(),
                    inputs,
                    output,
                    cube_count_plan.as_args(),
                    config,
                    dtypes,
                )
            }
        }
    }
    .is_ok()
}
